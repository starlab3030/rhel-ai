# InstructLab 시작

목차
* [ilab의 명령줄 인터페이스 설치](./start-with-instructlab.md#ilab의-명령줄-인터페이스-설치)<br>
* [ilab 설치](./start-with-instructlab.md#ilab-설치)<br>
* [ilab 초기화](./start-with-instructlab.md#ilab-초기화)<br>
* [모델 다운로드](./start-with-instructlab.md#모델-다운로드)<br>
* [모델 제공 (Serving the model)](./start-with-instructlab.md#모델-제공-serving-the-model)<br>
* [모델과 채팅하기](./start-with-instructlab.md#모델과-채팅하기)<br>

<br>
<hr>
<br>

## ilab의 명령줄 인터페이스 설치

**ilab**
* LLM 개발자 경험과 워크플로를 구현하는 CLI 도구
* 파이썬으로 작성되었으며 다음 아키텍처에서 작동
  - 애플 M1/M2/M3 Mac
  - 리눅스 시스템

**시스템 요구 사항**
* C++ 컴파일러
* 파이썬 3.9 이상
* 약 60GB 디스크 공간(전체 프로세스)
  - 디스크 공간 요구 사항은 여러 요인에 따라 다름
  - 모델에 공급할 데이터를 생성하는 동시에 모델을 로컬 시스템에 보관
  - 해당 워크숍에서 작업하는 모델의 크기는 약 5GB
<br>
<br>

## ilab 설치

### 1. 다음 명령어를 실행하여 파이썬 가상 환경을 활성화

```bash
cd ~/instructlab/
cat venv/bin/activate
source venv/bin/activate
```

activate 파이썬 파일
```python
# This file must be used with "source bin/activate" *from bash*
# you cannot run it directly

deactivate () {
    # reset old environment variables
    if [ -n "${_OLD_VIRTUAL_PATH:-}" ] ; then
        PATH="${_OLD_VIRTUAL_PATH:-}"
        export PATH
        unset _OLD_VIRTUAL_PATH
    fi
    if [ -n "${_OLD_VIRTUAL_PYTHONHOME:-}" ] ; then
        PYTHONHOME="${_OLD_VIRTUAL_PYTHONHOME:-}"
        export PYTHONHOME
        unset _OLD_VIRTUAL_PYTHONHOME
    fi

    # Call hash to forget past commands. Without forgetting
    # past commands the $PATH changes we made may not be respected
    hash -r 2> /dev/null

    if [ -n "${_OLD_VIRTUAL_PS1:-}" ] ; then
        PS1="${_OLD_VIRTUAL_PS1:-}"
        export PS1
        unset _OLD_VIRTUAL_PS1
    fi

    unset VIRTUAL_ENV
    unset VIRTUAL_ENV_PROMPT
    if [ ! "${1:-}" = "nondestructive" ] ; then
    # Self destruct!
        unset -f deactivate
    fi
}

# unset irrelevant variables
deactivate nondestructive

VIRTUAL_ENV="/home/instruct/instructlab/venv"
export VIRTUAL_ENV

_OLD_VIRTUAL_PATH="$PATH"
PATH="$VIRTUAL_ENV/bin:$PATH"
export PATH

# unset PYTHONHOME if set
# this will fail if PYTHONHOME is set to the empty string (which is bad anyway)
# could use `if (set -u; : $PYTHONHOME) ;` in bash
if [ -n "${PYTHONHOME:-}" ] ; then
    _OLD_VIRTUAL_PYTHONHOME="${PYTHONHOME:-}"
    unset PYTHONHOME
fi

if [ -z "${VIRTUAL_ENV_DISABLE_PROMPT:-}" ] ; then
    _OLD_VIRTUAL_PS1="${PS1:-}"
    PS1="(venv) ${PS1:-}"
    export PS1
    VIRTUAL_ENV_PROMPT="(venv) "
    export VIRTUAL_ENV_PROMPT
fi

# Call hash to forget past commands. Without forgetting
# past commands the $PATH changes we made may not be respected
hash -r 2> /dev/null
```

실행 결과
```
[instruct@bastion ~]$ cd ~/instructlab/

[instruct@bastion instructlab]$ cat venv/bin/activate

...<snip>...

[instruct@bastion instructlab]$ source venv/bin/activate

(venv) [instruct@bastion instructlab]$ 
```
<br>

### 2. *ilab* 명령어를 실행하여 정상적으로 설치되었는 지 확인

```bash
ilab
```

실행 결과
```
(venv) [instruct@bastion instructlab]$ ilab
Usage: ilab [OPTIONS] COMMAND [ARGS]...

  CLI for interacting with InstructLab.

  If this is your first time running ilab, it's best to start with `ilab init`
  to create the environment.

Options:
  --config PATH  Path to a configuration file.  [default: config.yaml]
  --version      Show the version and exit.
  --help         Show this message and exit.

Commands:
  config    Command Group for Interacting with the Config of InstructLab.
  data      Command Group for Interacting with the Data generated by...
  model     Command Group for Interacting with the Models in InstructLab.
  sysinfo   Print system information
  taxonomy  Command Group for Interacting with the Taxonomy of InstructLab.

Aliases:
  chat: model chat
  convert: model convert
  diff: taxonomy diff
  download: model download
  generate: data generate
  init: config init
  serve: model serve
  test: model test
  train: model train
(venv) [instruct@bastion instructlab]$
```
<br>
<br>

## ilab 초기화

```bash
ilab config init
```

실행 결과
```
(venv) [instruct@bastion instructlab]$ ilab config init
Welcome to InstructLab CLI. This guide will help you to setup your environment.
Please provide the following values to initiate the environment [press Enter for defaults]:
Path to taxonomy repo [taxonomy]: 
Generating `config.yaml` in the current directory...
Initialization completed successfully, you're ready to start using `ilab`. Enjoy!

(venv) [instruct@bastion instructlab]$ 
```

> [!NOTE]
> *ENTER*를 눌러 기본값 설정을 할 수 있음

초기화 단계에서는 여러 가지 일이 발생합니다.
* 기본 택소노미(taxonomy: 분류학)는 로컬 파일 시스템에 위치
* 구성 파일(config.yaml)은 현재 디렉토리에 생성

구성 파일 확인
```bash
ls ~/instructlab/config.yaml
yq -y . ~/instructlab/config.yaml 
```

실행 결과
```
(venv) [instruct@bastion instructlab]$ ls ~/instructlab/config.yaml
/home/instruct/instructlab/config.yaml

(venv) [instruct@bastion instructlab]$ yq -y . ~/instructlab/config.yaml 

...<snip>...

(venv) [instruct@bastion instructlab]$
```

config.yaml 파일
```yaml
chat:
  context: default
  greedy_mode: false
  logs_dir: data/chatlogs
  max_tokens: null
  model: models/merlinite-7b-lab-Q4_K_M.gguf
  session: null
  vi_mode: false
  visible_overflow: true
general:
  log_level: INFO
generate:
  chunk_word_count: 1000
  model: models/merlinite-7b-lab-Q4_K_M.gguf
  num_cpus: 10
  num_instructions: 100
  output_dir: generated
  prompt_file: prompt.txt
  seed_file: seed_tasks.json
  taxonomy_base: origin/main
  taxonomy_path: taxonomy
serve:
  gpu_layers: -1
  host_port: 127.0.0.1:8000
  max_ctx_size: 4096
  model_path: models/merlinite-7b-lab-Q4_K_M.gguf
```
<br>
<br>

## 모델 다운로드

InstructLab 환경이 구성되면, API 요청에 대한 모델 서버로 사용하거나 새 모델을 훈련하는 데 도움이 되도록 양자화된(압축 및 최적화된) 모델을 로컬 디렉토리에 다운로드할 수 있습니다.

모델을 지정하여 다운로드 하기
```bash
ilab model download --repository instructlab/granite-7b-lab-GGUF --filename=granite-7b-lab-Q4_K_M.gguf
ls -lh models/
```

실행 결과
```
(venv) [instruct@bastion instructlab]$ ilab model download --repository instructlab/granite-7b-lab-GGUF --filename=granite-7b-lab-Q4_K_M.gguf
Downloading model from instructlab/granite-7b-lab-GGUF@main to models...
Downloading 'granite-7b-lab-Q4_K_M.gguf' to 'models/.cache/huggingface/download/granite-7b-lab-Q4_K_M.gguf.6adeaad8c048b35ea54562c55e454cc32c63118a32c7b8152cf706b290611487.incomplete'
INFO 2024-10-08 00:03:13,373 file_download.py:1908: _download_to_tmp_and_move Downloading 'granite-7b-lab-Q4_K_M.gguf' to 'models/.cache/huggingface/download/granite-7b-lab-Q4_K_M.gguf.6adeaad8c048b35ea54562c55e454cc32c63118a32c7b8152cf706b290611487.incomplete'
granite-7b-lab-Q4_K_M.gguf: 100%|█████████████████████████████████████████████| 4.08G/4.08G [00:09<00:00, 429MB/s]
Download complete. Moving file to models/granite-7b-lab-Q4_K_M.gguf
INFO 2024-10-08 00:03:22,968 file_download.py:1924: _download_to_tmp_and_move Download complete. Moving file to models/granite-7b-lab-Q4_K_M.gguf

(venv) [instruct@bastion instructlab]$ ls -lh models/
total 3.9G
-rw-r--r--. 1 instruct users 3.9G Oct  8 00:03 granite-7b-lab-Q4_K_M.gguf

(venv) [instruct@bastion instructlab]$ 
```
* 허깅페이스(HuggingFace)의 instructlab 조직에서 모델을 다운로드

다운로드한 모델을 가지고 작업이 진행 가능합니다.
* 모델을 제공(serve)
  - 단순히 API 호출을 하는 것과 유사하게 다른 프로그램이 데이터와 상호 작용할 수 있도록 하는 서버를 실행한다는 것
* 모델과 채팅
<br>
<br>

## 모델 제공 (Serving the model)

다음 명령을 실행하여 모델을 제공
```bash
ilab model serve --model-path models/granite-7b-lab-Q4_K_M.gguf
```

실행 결과
```
(venv) [instruct@bastion instructlab]$ ilab model serve --model-path models/granite-7b-lab-Q4_K_M.gguf
INFO 2024-10-08 00:14:31,456 serve.py:51: serve Using model 'models/granite-7b-lab-Q4_K_M.gguf' with -1 gpu-layers and 4096 max context size.
INFO 2024-10-08 00:14:32,516 server.py:218: server Starting server process, press CTRL+C to shutdown server...
INFO 2024-10-08 00:14:32,516 server.py:219: server After application startup complete see http://127.0.0.1:8000/docs for API.

```
* serve 명령은 선택 사항인 -–model-path 인수를 사용
* 해당 랩에서는 Granite 모델(granite-7b)을 제공
* 모델 경로가 제공되지 않으면 config.yaml 파일의 기본값을 사용
<br>
<br>

## 모델과 채팅하기

### 1. 별도의 터미널에서 채팅 명령 실행

별도의 터미널 창을 사용하여 파이썬 가상 환경을 다시 활성화하고, ilab 채팅 명령을 실행
```bash
cd ~/instructlab/
source venv/bin/activate
ilab model chat -m models/granite-7b-lab-Q4_K_M.gguf
```

실행 결과
```
[instruct@bastion ~]$ cd ~/instructlab/

[instruct@bastion instructlab]$ source venv/bin/activate

(venv) [instruct@bastion instructlab]$ ilab model chat -m models/granite-7b-lab-Q4_K_M.gguf
╭─────────────────────────────────────────── system ───────────────────────────────────────────╮
│ Welcome to InstructLab Chat w/ MODELS/GRANITE-7B-LAB-Q4_K_M.GGUF (type /h for help)          │
╰──────────────────────────────────────────────────────────────────────────────────────────────╯
>>>                                                                                 [S][default]
```
* 채팅 프롬프트 확인
<br>

### 2. 질문을 통해 모델과 상호 작용

실행 결과
```
>>> What is openshift in 20 words or less?                                          [S][default]
╭───────────────────────────── models/granite-7b-lab-Q4_K_M.gguf ──────────────────────────────╮
│ Openshift: A container application platform for rapid deployment, scaling, and management of │
│ applications across hybrid cloud environments.                                               │
╰────────────────────────────────────────────────────────────────────── elapsed 0.524 seconds ─╯
>>>                                                                                 [S][default]
```
<br>
<br>

------
[차례](../README.md) &nbsp;&nbsp;&nbsp;&nbsp; [<< RHSC 키노트 데모 소개 <<](./introdution-of-lab.md) &nbsp;&nbsp;&nbsp;&nbsp; [>> AI를 앱에 통합 >>](./integrate-ai-into-app.md)